<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>系统部署 on SuperSonic</title><link>http://localhost:1313/docs/%E7%B3%BB%E7%BB%9F%E9%83%A8%E7%BD%B2/</link><description>Recent content in 系统部署 on SuperSonic</description><generator>Hugo</generator><language>en-us</language><atom:link href="http://localhost:1313/docs/%E7%B3%BB%E7%BB%9F%E9%83%A8%E7%BD%B2/index.xml" rel="self" type="application/rss+xml"/><item><title>Docker部署</title><link>http://localhost:1313/docs/%E7%B3%BB%E7%BB%9F%E9%83%A8%E7%BD%B2/docker%E9%83%A8%E7%BD%B2/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://localhost:1313/docs/%E7%B3%BB%E7%BB%9F%E9%83%A8%E7%BD%B2/docker%E9%83%A8%E7%BD%B2/</guid><description>部署前提 # 下载安装Docker和Docker Compose，并启动docker
Docker版本：26.0.0+
Docker Compose：v2.26.1+
注意 1 如果报如下错:
Cannot connect to the Docker daemon at unix:///Users/lexluo/.docker/run/docker.sock. Is the docker daemon running?
说明docker没有启动
2 supersonic_db_init主要作用是数据库数据初始化，不是常驻服务。执行完成后，exited是正常现象。
启动部署 # 进入docker目录，执行脚步启动 # docker-compose up -d 注意 支持按SuperSonic版本启动，不指定版本默认是：latest
SUPERSONIC_VERSION=0.9.2-SNAPSHOT docker-compose up -d 注意 镜像下载慢，可配置国内镜像源，许多国内的云服务提供商提供了Docker镜像加速服务。你可以配置Docker使用这些镜像源来加速下载。 以阿里云为例：
登录阿里云控制台，进入容器镜像服务。 在左侧导航栏中选择“镜像加速器”。 复制加速器地址，例如 https://.mirror.aliyuncs.com。 编辑 Docker 配置文件 /etc/docker/daemon.json，添加以下内容：
{ &amp;ldquo;registry-mirrors&amp;rdquo;: [&amp;ldquo;https://.mirror.aliyuncs.com&amp;rdquo;] } 重启 Docker 服务：
sudo systemctl daemon-reload
sudo systemctl restart docker 运维操作 # 1 查看进程运行状况：
docker-compose ps 正常会出现三个服务： 2 查看进程日志信息：</description></item><item><title>编译构建</title><link>http://localhost:1313/docs/%E7%B3%BB%E7%BB%9F%E9%83%A8%E7%BD%B2/%E7%BC%96%E8%AF%91%E6%9E%84%E5%BB%BA/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://localhost:1313/docs/%E7%B3%BB%E7%BB%9F%E9%83%A8%E7%BD%B2/%E7%BC%96%E8%AF%91%E6%9E%84%E5%BB%BA/</guid><description> 编译构建 # SuperSonic为二次开发提供两种编译构建方式：
在开发调试场景，直接从本地IDE启动； 在开发部署场景，从源代码编译打包。 本地IDE启动 # sh assembly/bin/supersonic-build.sh webapp 执行构建webapp 注：前端编译需要Node，推荐安装版本v20.16.0 IDE本地启动Java类com.tencent.supersonic.StandaloneLauncher 注：后端编译需要JDK，推荐安装版本11 访问浏览器：http://localhost:9080 源代码编译包启动 # 下载相应版本source code 执行编译脚本：sh assembly/bin/supersonic-build.sh 注：前端编译需要Node，推荐安装版本v20.16.0；后端编译需要JDK，推荐安装版本11 编译完成后从assembly/build目录获取release包 解压release包，unzip supersonic-standalone-{revision}.zip 进行release目录，执行启动脚本sh bin/supersonic-daemon.sh start 访问浏览器：http://localhost:9080 附加说明 # Windows环境均有提供对应的bat脚本, 执行即可。 Ubuntu环境, 启动方式同上, 若出现报错, 可尝试https://support.huaweicloud.com/intl/zh-cn/deployman_faq/deployman_faq_1016.html。 启动之后, 可以到logs目录下查看日志，确认启动正常。</description></item><item><title>配置DB</title><link>http://localhost:1313/docs/%E7%B3%BB%E7%BB%9F%E9%83%A8%E7%BD%B2/%E9%85%8D%E7%BD%AEdb/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://localhost:1313/docs/%E7%B3%BB%E7%BB%9F%E9%83%A8%E7%BD%B2/%E9%85%8D%E7%BD%AEdb/</guid><description> 配置DB # 注意
系统默认使用H2内存数据库, 重启后会丢失数据, 若需要替换为自己的MySQL, 请按以下进行配置.
1. 执行SQL脚本 # 初次配置DB请依次执行conf/db下schema-mysql.sql、 data-mysql.sql, 这两个脚本均为最新表结构
若是已配置过DB并部署好的服务, 可参考sql-update.sql, 这里会注明每次功能改动需要改动的表结构
2. 配置YAML文件 # conf下application-local.yaml中默认的DB配置为H2配置, 替换为自己的MySQL即可
spring: datasource: url: jdbc:mysql://localhost:3306/your_database?useUnicode=true&amp;amp;characterEncoding=UTF-8&amp;amp;useSSL=false&amp;amp;allowMultiQueries=true username: your_username password: your_password driver-class-name: com.mysql.jdbc.Driver</description></item><item><title>配置LLM</title><link>http://localhost:1313/docs/%E7%B3%BB%E7%BB%9F%E9%83%A8%E7%BD%B2/%E9%85%8D%E7%BD%AEllm/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://localhost:1313/docs/%E7%B3%BB%E7%BB%9F%E9%83%A8%E7%BD%B2/%E9%85%8D%E7%BD%AEllm/</guid><description>配置LLM # Chat Model # SuperSonic可以从两个粒度配置Chat Model：
1. 系统粒度 # 1.2.修改langchain4j.yaml配置文件方式 # 从0.9.4版本开始，langchain4j配置从application.yaml文件中单独抽取，方便用户配置；以langchain4j-local.yaml为例配置：
目前支持：open-ai、ollama两种方式； 1、open_ai 用于连接云端模型；通常情况下各云上模型会兼容open-ai协议 2、ollama 用于连接本地模型；由ollama适配不同的模型
注意 推荐使用open_ai、ollama；其他azure、qianfan、dashscope、zhipu方式理论上也支持，但是待验证； open-ai 配置方式：
langchain4j: open-ai: chat-model: base-url: ${OPENAI_API_BASE:demo} api-key: ${OPENAI_API_KEY:demo} model-name: ${OPENAI_MODEL_NAME:gpt-3.5-turbo} temperature: ${OPENAI_TEMPERATURE:0.0} timeout: ${OPENAI_TIMEOUT:PT60S} ollama 配置方式：
langchain4j: ollama: chat-model: base-url: ${OPENAI_API_BASE:demo} api-key: ${OPENAI_API_KEY:demo} model-name: ${OPENAI_MODEL_NAME:gpt-3.5-turbo} temperature: ${OPENAI_TEMPERATURE:0.0} timeout: ${OPENAI_TIMEOUT:PT60S} azure 配置方式：
langchain4j: azure-open-ai: chat-model: endpoint: https://xxx.openai.azure.com/ api-key: xxxx deployment-name: gpt-35-turbo max-tokens: 500 注意 以下方式配置，待验证： zhipu 配置方式：
langchain4j: zhipu: chat-model: base-url: base-url api-key: demo model-name: xxx temperature: 0.</description></item></channel></rss>