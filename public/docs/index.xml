<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Docs on SuperSonic</title><link>http://localhost:1313/docs/</link><description>Recent content in Docs on SuperSonic</description><generator>Hugo</generator><language>en-us</language><atom:link href="http://localhost:1313/docs/index.xml" rel="self" type="application/rss+xml"/><item><title>快速体验</title><link>http://localhost:1313/docs/%E5%BF%AB%E9%80%9F%E4%BD%93%E9%AA%8C/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://localhost:1313/docs/%E5%BF%AB%E9%80%9F%E4%BD%93%E9%AA%8C/</guid><description>快速体验#SuperSonic内置用于DEMO的语义模型和智能助理，因而只需要以下三步即可快速体验。
启动系统#下载相应版本release包 解压zip包，执行启动脚本：sh bin/supersonic-daemon.sh start 访问浏览器：http://localhost:9080 配置LLM#进入菜单“助理管理”，选择系统内置的DEMO助理“算指标” 点击“修改信息”，选择“大模型配置”，填入自己申请的大模型服务信息，包括“Model Name”、“Base URL”以及&amp;quot;API Key&amp;quot; 点击“确定”，保存助理大模型配置 问题对话#进入菜单“问答对话”，选择智能助理“算指标”
点击“新对话”，输入问题“近半个月sales部门访问量最高的用户是谁”
点击&amp;quot;LLM解析S2SQL&amp;quot;可以查看大模型生成的SQL</description></item><item><title>项目架构</title><link>http://localhost:1313/docs/%E9%A1%B9%E7%9B%AE%E6%9E%B6%E6%9E%84/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://localhost:1313/docs/%E9%A1%B9%E7%9B%AE%E6%9E%B6%E6%9E%84/</guid><description>项目架构#架构图#核心组件#Knowledge Base： 定期从语义模型中提取相关的模式信息，构建词典和索引，以便后续的模式映射。
Schema Mapper： 将自然语言文本在知识库中进行匹配，为后续的语义解析提供相关信息。
Semantic Parser： 理解用户查询并抽取语义信息，生成语义查询语句S2SQL。
Semantic Corrector： 检查语义查询语句的合法性，对不合法的信息做修正和优化处理。
Semantic Translator： 将语义查询语句翻译成可在物理数据模型上执行的SQL语句。
Chat Plugin： 通过第三方工具扩展功能。给定所有配置的插件及其功能描述和示例问题，大语言模型将选择最合适的插件。</description></item><item><title>FAQ</title><link>http://localhost:1313/docs/faq/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://localhost:1313/docs/faq/</guid><description>FAQ#项目有没有体验的地址？#A: Playground访问地址：http://117.72.46.148:9080
初始启动后为什么能显示DEMO问答对话？#A: 为了便于快速体验，系统内置DEMO语义模型，且实现了基于规则的解析器，所以不需要大模型也可以进行问答对话。不过，规则解析器能力有限，推荐仅用于测试验证，生产使用还是需要大模型解析。
是否自带大模型服务？#A: 项目内置langchain4j社区提供的demo API key，但单次请求openai大模型限制在1000 token，因而只能用于快速体验。要正常体验问答对话，请自行申请大模型服务。
支持哪些大模型服务？#A: 当前主要支持兼容open_ai接口协议的大模型服务，比如GPT、GLM、DeepSeek、Qwen、Moonshot等。文心和混元正在验证中，敬请期待。
是否支持文本知识库？#A: 当前主要聚焦于结构化数据的问答，文本数据将在未来版本加入支持。
是否支持多轮对话？#A: 自0.9.2版本起已经支持多轮对话，但默认是关闭的，需要在助理配置里开启。</description></item></channel></rss>