<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Docs on SuperSonic</title><link>http://localhost:1313/docs/</link><description>Recent content in Docs on SuperSonic</description><generator>Hugo</generator><language>en-us</language><atom:link href="http://localhost:1313/docs/index.xml" rel="self" type="application/rss+xml"/><item><title>快速体验</title><link>http://localhost:1313/docs/%E5%BF%AB%E9%80%9F%E4%BD%93%E9%AA%8C/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://localhost:1313/docs/%E5%BF%AB%E9%80%9F%E4%BD%93%E9%AA%8C/</guid><description> 快速体验 # SuperSonic内置用于DEMO的语义模型和智能助理，因而只需要以下三步即可快速体验。
启动系统 # 下载相应版本release包 解压zip包，执行启动脚本：sh bin/supersonic-daemon.sh start 访问浏览器：http://localhost:9080 注意 启动之前请安装好Java环境(JDK1.8)，Windows系统请到bin目录下执行.\supersonic-daemon.bat start 即可 测试LLM连通性 # 配置LLM # 进入菜单“助理管理”，选择系统内置的DEMO助理“来闲聊” 点击“修改信息”，选择“大模型配置”，填入自己申请的大模型服务信息，包括“Model Name”、“Base URL”以及&amp;quot;API Key&amp;quot; 点击“确定”，保存助理大模型配置 问题对话 # 进入菜单&amp;quot;问答对话&amp;quot;，选择智能助理“来闲聊” 随便输入文字，如何收到回复，则代表大模型连接成功 测试Text2SQL # 进入菜单“助理管理”，选择系统内置的DEMO助理“算指标”，配置LLM（与上节相同） 进入菜单“问答对话”，选择智能助理“算指标” 点击“新对话”，输入问题“近半个月sales部门访问量最高的用户是谁” 点击&amp;quot;LLM解析S2SQL&amp;quot;可以查看大模型生成的SQL</description></item><item><title>贡献指南</title><link>http://localhost:1313/docs/%E8%B4%A1%E7%8C%AE%E6%8C%87%E5%8D%97/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://localhost:1313/docs/%E8%B4%A1%E7%8C%AE%E6%8C%87%E5%8D%97/</guid><description>👍🎉 首先，感谢您花时间为本项目做出贡献！🎉👍
1. 创建issue # 在提交Issue之前，请先检查项目的Issue跟踪器，以确保没有其他人已经报告了相同的问题或请求了相同的功能。 Issue提交规范示例：
标题格式请用：【{模块名}】+标题内容 选择提交issue对应的Labels（如bug、documentation、question等） 选择Milestone迭代完成周期 2. Fork和Clone代码 # 进入supersonic github页面，点击页面右上角的&amp;quot;Fork&amp;quot;按钮。这将在你的GitHub账户下创建项目的一个副本。 在你的机器上clone Fork的仓库： git clone https://github.com/&amp;lt;your_github_name&amp;gt;/supersonic.git cd supersonic 将supersonic添加为本地仓库的远程分支upstream git remote add upstream https://github.com/tencentmusic/supersonic 同步远端主分支至本地 git pull upstream master --rebase 3. 修改提交 # 创建一个新的分支并修改代码，并推送到自己仓库
git checkout -b your-branch-name git add . git commit -m &amp;#34;(improvement | feature | fix)(headless | chat | common | launcher) &amp;lt;commit description&amp;gt;&amp;#34; git push origin your-branch-name commit规范:
commit请使用英文，长度控制在50字符以内 commit提交格式 格式：(type)(scope) commit description type: 提交类型，如improvement、feature、fix、doc、style、test等 scope: 修改范围，如headless、chat、common、launcher模块 commit description：提交的详细描述，可以包含更多的细节和上下文。 4.</description></item><item><title>项目架构</title><link>http://localhost:1313/docs/%E9%A1%B9%E7%9B%AE%E6%9E%B6%E6%9E%84/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://localhost:1313/docs/%E9%A1%B9%E7%9B%AE%E6%9E%B6%E6%9E%84/</guid><description>项目架构 # 架构图 # 核心组件 # Knowledge Base： 定期从语义模型中提取相关的模式信息，构建词典和索引，以便后续的模式映射。
Schema Mapper： 将自然语言文本在知识库中进行匹配，为后续的语义解析提供相关信息。
Semantic Parser： 理解用户查询并抽取语义信息，生成语义查询语句S2SQL。
Semantic Corrector： 检查语义查询语句的合法性，对不合法的信息做修正和优化处理。
Semantic Translator： 将语义查询语句翻译成可在物理数据模型上执行的SQL语句。
Chat Plugin： 通过第三方工具扩展功能。给定所有配置的插件及其功能描述和示例问题，大语言模型将选择最合适的插件。
Chat Memory： 将历史的查询轨迹进行封装，可被召回作为few-shot样例嵌入提示词。</description></item><item><title>chat-sdk集成</title><link>http://localhost:1313/docs/chat-sdk%E9%9B%86%E6%88%90/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://localhost:1313/docs/chat-sdk%E9%9B%86%E6%88%90/</guid><description>chat-sdk 集成 # 问答对话页支持以下两种方式集成：
npm 组件包集成 iframe 嵌入 npm 组件包集成 # 进入到/webapp/packages/chat-sdk 目录，修改 package.json { &amp;#34;name&amp;#34;: &amp;#34;xxx-chat-sdk&amp;#34;, &amp;#34;version&amp;#34;: &amp;#34;x.x.x&amp;#34;, ... } 执行npm run build 执行npm publish，将组件发布到 npm 仓库 在 react 前端项目执行npm install xxx-chat-sdk，安装 chat-sdk 组件包 在 react 前端项目中引入 chat-sdk 包 import { Chat } from &amp;#39;xxx-chat-sdk&amp;#39;; const ChatPage = () =&amp;gt; { return ( &amp;lt;Chat token=&amp;#34;xxx&amp;#34; /&amp;gt; ); }; export default ChatPage; 通过以上步骤便可以将问答对话页集成到业务系统中了
提示
npm 包名 name 和版本 version 需要自行根据项目业务需要进行设置 token 为 supersonic 用户登录认证 token iframe 嵌入 # 将以下代码加入业务系统前端项目组件中</description></item><item><title>FAQ</title><link>http://localhost:1313/docs/faq/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://localhost:1313/docs/faq/</guid><description>FAQ # 项目有没有体验的地址？ # A: Playground访问地址：http://117.72.46.148:9080
初始启动后为什么能显示DEMO问答对话？ # A: 为了便于快速体验，系统内置DEMO语义模型，且实现了基于规则的解析器，所以不需要大模型也可以进行问答对话。不过，规则解析器能力有限，推荐仅用于测试验证，生产使用还是需要大模型解析。
是否自带大模型服务？ # A: 项目内置langchain4j社区提供的demo API key，但单次请求openai大模型限制在1000 token，因而只能用于快速体验。要正常体验问答对话，请自行申请大模型服务。
支持哪些大模型服务？ # A: 当前主要支持兼容open_ai接口协议的大模型服务，比如GPT、GLM、DeepSeek、Qwen、Moonshot等。文心和混元正在验证中，敬请期待。
是否支持文本知识库？ # A: 当前主要聚焦于结构化数据的问答，文本数据将在未来版本加入支持。
是否支持多轮对话？ # A: 自0.9.2版本起已经支持多轮对话，但默认是关闭的，需要在助理配置里开启。
重启系统后为什么配置的助理/模型数据丢失了？ # A: 系统默认使用H2内存数据库，如果需要持久化存储需配置DB，参考文档
系统默认的账号和密码是什么？ # A: 系统默认创建的用户有admin, jack, tom, lucy, alice，密码都是：123456
如果要用我自己的数据进行测试，我至少需要经过哪些步骤 # A: 连接数据库 -&amp;gt; 构造模型(创建指标和维度) -&amp;gt; 组装数据集 -&amp;gt; 创建助理和工具
是否可以提供接口供第三方应用调用？ # A: 可以，启动系统后查看swagger接口文档：http://localhost:9080/swagger-ui/index.html
有哪些国内的大模型服务对接？ # A: 当前我们验证过一些主流大模型服务，其申请链接如下表所示：
提供商 API申请链接 推荐模型 智谱AI https://open.bigmodel.cn/api/paas/v4 glm-4 阿里云 https://dashscope.aliyuncs.com/compatible-mode/v1 qwen-max 幻方 https://api.</description></item><item><title/><link>http://localhost:1313/docs/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E7%BD%AE/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://localhost:1313/docs/%E7%B3%BB%E7%BB%9F%E8%AE%BE%E7%BD%AE/</guid><description>快速补充中&amp;hellip;</description></item></channel></rss>